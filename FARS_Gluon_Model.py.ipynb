{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code illustrating import of gluon library\n",
    "# !sudo pip install mxnet\n",
    "from __future__ import division\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, ndarray\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decide on some graphic options. Since these data sets have so many columns, it might be nice to see more of them than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 110)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're reading in our data files and saving them as variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = pd.read_csv('data/person.csv')\n",
    "accidents = pd.read_csv('data/accident.csv')\n",
    "vehicles = pd.read_csv('data/vehicle.csv', encoding ='latin1')  # In case you get encoding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a baseline assessment of a model's ability to accurately classify an Accident without considering information contained within the Person or Vehicle tables.  Let's prepare our data for the Gluon multi-class classification model.\n",
    "\n",
    "We will want to use the following features of the Accident table:\n",
    "#Page 32 of FARS Data Manual\n",
    "\n",
    "    'PEDS': Persons not in vehicles\n",
    "    'PERNOTMVIT': Non-motorists in crash\n",
    "    'VE_TOTAL': All vehicles in crash\n",
    "    'VE_FORMS': Number of vehicles in transport\n",
    "    'PVH_INVL': Nubmer of parked, working vehicles\n",
    "    'PERSONS': Number of persons involved\n",
    "    'PERMVIT': Number of motorists in accident\n",
    "    'COUNTY': County where accident occured\n",
    "    'CITY': City where accident occured\n",
    "    'MONTH': Month of accident\n",
    "    'DAY': Day of month of accident\n",
    "    'DAY_WEEK': Day of week of accident\n",
    "    'YEAR': Year of crash\n",
    "    'HOUR': Hour of crash\n",
    "    'MINUTE': Minute of hour of crash\n",
    "    'TWAY_ID': Traffic Direction at time of crash\n",
    "    'TWAY_ID2': Traffic Direction at time of crash\n",
    "    # Not in data, but in data manual\n",
    "    # 'CL_TWAY': Routing signal at time of accident\n",
    "    'ROUTE': Routing signal at time of accident\n",
    "    'SP_JUR': Special Jurisdiction\n",
    "    'MILEPT' : Closest mile point\n",
    "    'LATITUDE' : Latitute\n",
    "    'LONGITUD': Longitude\n",
    "    'TYP_INT': Type of intersection\n",
    "    'REL_ROAD': Relation to Trafficway\n",
    "    'C_M_ZONE': Work Zone\n",
    "    'WRK_ZONE': Work Zone\n",
    "    'LGT_COND': Light condition\n",
    "    'WEATHER': Weather condition\n",
    "    'WEATHE1': Weather condition\n",
    "    'WEATHE2': Weather condition\n",
    "\n",
    "    # Label\n",
    "    'MAN_COLL': Manner of collision\n",
    "    'HARM_EV': First injury or damage producing event in crash\n",
    "    \n",
    "    \n",
    "    \n",
    "*All features have scale/index discontinuities over the history of the data; this must be accounted for on a feature-by-feature basis\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = [\n",
    "    'PEDS',\n",
    "    'PERNOTMVIT',\n",
    "    'VE_TOTAL',\n",
    "    'VE_FORMS',\n",
    "    'PVH_INVL',\n",
    "    'PERSONS',\n",
    "    'PERMVIT',\n",
    "    'COUNTY',\n",
    "    'CITY',\n",
    "    'MONTH',\n",
    "    'DAY',\n",
    "    'DAY_WEEK',\n",
    "    'HOUR',\n",
    "    #Following 2 features are the same over different time horizons\n",
    "#     'TWAY_ID',\n",
    "#     'TWAY_ID2',\n",
    "    #Following 2 features are the same over different time horizons\n",
    "#     'CL_TWAY',\n",
    "    'ROUTE',\n",
    "    'TYP_INT',\n",
    "    'LGT_COND',\n",
    "    #Following 3 features are the same over different time horizons\n",
    "    'WEATHER',\n",
    "#     'WEATHER1',\n",
    "#     'WEATHER2'\n",
    "    \n",
    "    # LABELS: We can choose which to prediect\n",
    "    # Manner of Collision\n",
    "    'MAN_COLL',\n",
    "    # First Harmul Event\n",
    "#     'HARM_EV'\n",
    "]\n",
    "\n",
    "df_accidents = accidents[sub_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a sparse dataframe with features and labels (HARM_EV), we'll want to encode our categorical feautures.  Before we do that, let's decrease some of the sparsity by removing features that are missing more than half of their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost all instances of 0 map to None, so we will remove columns that have an abundance of them\n",
    "def trim_features(data_frame, ratio):\n",
    "    print 'Begining columns:', len(data_frame.columns)\n",
    "    rows = data_frame.shape[0]\n",
    "    for col in data_frame.columns:\n",
    "        non_zeros = data_frame[col].astype(bool).sum(axis=0)\n",
    "        # If there are more zeros than a given ratio, drop column\n",
    "        if (non_zeros/rows)<ratio:\n",
    "            data_frame.drop([col], axis=1, inplace=True)\n",
    "    \n",
    "    print 'Ending columns:', len(data_frame.columns)\n",
    "    return data_frame\n",
    "        \n",
    "    \n",
    "# Trim geographical columns\n",
    "def trim_geo(data_frame, columns):\n",
    "    for col in columns:\n",
    "        data_frame[col] = data_frame[col].apply(lambda x: 0 if x>9995 else x)\n",
    "    return data_frame\n",
    "        \n",
    "\n",
    "# TODO: trim_geo on CITY too\n",
    "df_accidents_trimmed = trim_geo(df_accidents_trimmed, ['COUNTY'])\n",
    "df_accidents_trimmed = trim_features(df_accidents, 0.5)\n",
    "\n",
    "df_accidents_trimmed.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have semi-dense data, let's one-hot encode our cateogrical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_feature_classes = {\n",
    "    'COUNTY': 999,\n",
    "    'CITY': 999,\n",
    "    'MONTH': 12,\n",
    "    'DAY': 31,\n",
    "    'DAY_WEEK': 7,\n",
    "    'HOUR': 24,\n",
    "    'ROUTE': 9,\n",
    "    'TYP_INT': 10,\n",
    "    'LGT_COND': 9,\n",
    "    'WEATHER': 14,\n",
    "    \n",
    "    # LABEL\n",
    "    'MAN_COLL': 12,\n",
    "    'HARM_EV': 100\n",
    "}\n",
    "\n",
    "def one_hot_encode_matrix(feature_matrix, label):\n",
    "    pass\n",
    "\n",
    "df_accidents_trimmed = pd.get_dummys(df_accidents_trimmed)\n",
    "print(sub_feature_classes = {\n",
    "    'COUNTY': 999,\n",
    "    'CITY': 999,\n",
    "    'MONTH': 12,\n",
    "    'DAY': 31,\n",
    "    'DAY_WEEK': 7,\n",
    "    'HOUR': 24,\n",
    "    'ROUTE': 9,\n",
    "    'TYP_INT': 10,\n",
    "    'LGT_COND': 9,\n",
    "    'WEATHER': 14,\n",
    "    \n",
    "    # LABEL\n",
    "    'MAN_COLL': 12,\n",
    "    'HARM_EV': 100\n",
    "}\n",
    "\n",
    "def one_hot_encode_matrix(feature_matrix, label):\n",
    "    pass\n",
    "\n",
    "df_accidents_trimmed = pd.get_dummys(df_accidents_trimmed)\n",
    "df_accidents_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
